\section{Test Methodology}
\subsection{Overview}
The testing is mainly performed by the test team and the testing cross functional team. The test team will have all the responsibility of testing from unit testing to acceptance testing. In the testing cross functional team, we have a analyst and software quality manager which will help validation and verification in higher level testing. The testing is done iterative which mean that all levels of testing is done in each sprint, starting with unit-level testing and finishing with testing the present application with the customer to validate our requirements. This will help us to continuously improve both our application and our testing through each iteration.
\subsection{Test Levels}
In this chapter the different test levels are presented and also which test and tools that will be used in the different levels. The different testing levels are unit testing, module testing, system testing and acceptance testing.
\subsubsection{Unit testing}
\noindent Unit testing will occur when a developer is doing a merge request to their specific cross functional team branch. Together with the unit testing, a peer review of the code is done by a developer to ensure that the functionality is correct and that the code is following company standards. In addition a pipeline with automated test is used according to continuous delivery. These test should focus on black box testing and will test the most basic functionality of the application for every merge request. The test are written in angular and are executed with karma. The main unit testing will focus on GUI testing through exploratory testing where the tester will try the new unit such as clicking a new button and seeing if the response is right. When performing exploratory test it is important to try as many testing sequence as possible because the user can cause all these sequences.\newline

\noindent From iteration 3 and forward the new cross-functional testing team will be responsible for the unit testing. The customer wants the project to have a major focus on user experience and usability of the system. Therefore, the testing will not focus on black box testing aside from the automated test. \newline

\noindent The work flow for testing new merge requests:\\
 \emph{The developer posts a merge request in GitLab. The automated tests in the pipeline is performed. A company member performs a peer review according to the set up rules. A tester performs a exploratory test on the new feature. If a small fault is found then a comment is posted on the merge request and the developer how posted the merge is responsible for fixing the comment before the merge can be done. If a major fault is found, a fault that takes approximated over 2 hours then a new issue is posted about the bug and the developer is assigned to the issue.} \newline

\subsubsection{Module Testing}
The module testing is the test of the integration between several units which verifies the module design. The testing will follow the top-down approach were we use Selenium IDE test cases. This will be used to test so that the different units will fit together. Test cases will be set up to test the whole application. This is done to make sure that new functionality does not affect already existing.\\

\noindent The test team is responsible for running the Selenium tests. These tests are done simultaneously as the unit test, when a merge request is posed in gitlab. Selenium is used to help reduce the workload for the tester. In a event-driven environment the user can cause events in different order which mean that there are a lot of different test cases. Therefore, the test team sets up test cases in Selenium IDE that can be done for every merge request. The Selenium test is also integrated in the pipeline to maximize the automated nature of the testing. 

\subsubsection{System testing}
The UX-team is responsible of the system testing which will verify the system's architecture and high-level design. This chapter is dividend in to two sections, function testing and performance testing. This testing level verifies the requirements. \newline

\noindent\textbf{Function testing}\\
To test functional requirements, functional testing is done. This is done to make sure that the application meets the requirements that are made by the analyst team. Because the developed application should focus on the usability and visualising data then this test will also be done exploratory. The exploratory function testing will be done by going through the requirement list and the UX-team will either mark the requirement as done or not. We are doing exploratory testing for this phase because the application has a major focus on the front-end. The exploratory testing is done both in web browser and iPad mode. This is done at the end of each sprint to understand which requirements that are done and which are not. This will enhance the traceability between the requirements and the developed application. \\

\noindent Two members from the UX-team work together when reviewing requirements. By looking through the closed issues on GitLab, requirements to be tested can be found since every issue is linked to a requirement by the requirement code (e.g RC-002-001). The component is then reviewed, both on a web browser setting and in an iPad setting. If the component fulfills the requirement and works in both settings, the requirement is passed and the issue is marked by a "passed review" label on Gitlab. If any faults are discovered, the review is failed and marked by a "failed review" label on GitLab. Additionaly, a comment describing why the review failed is published and the issue is reopened to allow the assigned developer to fix the issues. If needed, the UX-team develops a prototype on Figma to assist the developer. This is done every iteration to make sure that passed requirements remain correct and that failed reviews eventually becomes passed as well. \\ 


\noindent\textbf{Performance testing}\\
To test non-functional requirements, performance testing is done. This test is done to reduce performance bottlenecks. The non-functional requirements will be tested in the same way as the functional requirement if that is possible. If it is not possible the sufficient test will be performed to verify the requirement. Because different non-functional requirements needs different test to verify it the test will be presented in the Verification of requirements file. \\

\noindent\textbf{Traceability}\\
To keep track and trace which components have been accepted throughout the process the UX-team will be using a work sheet, found in output folder on teams, where every requirement is present. The sheet consists of the requirement, a date of the latest review, who it is reviewed by and if the requirement has passed the review. It will also include a link to the relevant issue in git with all the relevant info of who developed, tested and peer-reviewed the code. \\

\subsubsection{Acceptance testing}
To validate the requirements the test team will perform acceptance testing. These test are performed with the customer to understand their true needs and wants. \newline

\noindent The acceptance test will be performed with the concurrent think aloud method. To get a quantitative result and measure the usability of the application a SUS-test will also be part of the acceptance test. To conclude that our developed application has a sufficient level of usability the SUS-test must achieve a score of at least X(not yet decided) for the final product. The concurrent think aloud questions and SUS-test will be added as a appendix.\newline

\noindent The test will be conducted with the customer after each iteration to gather their response. Because the test is done after each iteration this enables the developer to get feedback of the not-yet-complete application by the customer. This will hopefully make the application tailored for the customer. The developed application will be used by people with different professions and technical experience. Therefore, it is important to conduct these acceptance test with different level of technical experience and profession to get a complete picture of the true needs of the customer. Unfortunately can the customer not provide people with different profession due to specific profession does not have the time to spare. Therefore, some perspectives can be lost nonetheless the doctors, nurses and assistant nurses works close together and can give some insight on what other profession need. \newline

\noindent Dates for test with customer:\newline
\textbf{After iteration 1}\\
Meeting with customer, IT-staff and nurses participated: 11/10 - 21\newline
\textbf{After iteration 2}\\
Acceptance test 1 with nurse: 11/11 - 21\newline
Acceptance test 2 with nurse: 12/11 - 21\newline
Acceptance test 3: 15/11 - 21\newline
\textbf{After iteration 3}\\
Purpose date for acceptance test: 22/11 - 21\newline
\textbf{After iteration 4, Final product}\\
Purposed date for acceptance testing: 3/12\newline

\noindent After iteration 1 the application was working but there were to few features to perform worth-while CTA and SUS testing. Therefore, after iteration 1, the application was shown to the customer along with the prototype from the tollgate meeting. The meetings purpose was to give the customer an opportunity elaborate on their specific needs for different parts of the website, both functional and design related. From iteration 2 and forward the customer acceptance testing will all follow the same structure. The customer will be given a certain amount of task that they will perform on the application while performing CTA. Afterwards, they will do a SUS-test. The task that the customer will be given can differ between the iteration because more feature will be developed over time thus, we want to include these feature in the test. \\

\noindent Each test with the customer will result in a acceptance test report. The different test reports for each test occasion will be summarized to a single test report that will be distributed to the whole company. This test report will be the foundation of changes in requirements and UX-design for the subsequent sprint. The test report after iteration 4 will show if the usability requirements.

\begin{comment}
\noindent (Between the tests with the customer, user tests will also be performed on other test objects than the customer. This test will test the progress of the different cross-functional teams and will be done by each tester in that cross-functional team.) Not sure we will use this
\end{comment}

\subsection{Bug Triage}
Bugs found during the testing procedure must be solved or have the underlying code generating the bug removed. This is due to all testing (except acceptance testing) taking place when a merge request is created. If a bug is found, the merge request is not approved by the tester. The merge request must then be edited to solve the bug or it is not to be merged at all. Bugs found outside of the testing procedure (e.g by non-testers) shall be reported to the testing team which will investigate the bug, create a Gitlab issue explaining what the bug is, steps to reproduce it, suspected underlying issue and deadline for when it must be solved. This is usually set to the next iteration deadline as known bugs shall not be present during acceptance testing with the customer. The Gitlab issue is assigned to the author of the code. 

\subsection{Suspension Criteria and Resumption Requirements}
Due to testers only working on testing and the small, limited number of functions in the application the suspension criteria is only a complete system failure rendering the application non-functional. Testers only working on testing means that continued runs after a program is not working correctly is reasonable in our time schedule. This is supported by the fact of a small, limited number of functions making each test short. This means that the only resumption criteria is when a non-functional program is made functional and thereby resuming testing.    
\subsubsection{Exam period, 19/10-21 $\xrightarrow{}$ 30/10-21}
During the exam period neither developers nor testers will have time to perform testing or programming because they will study for their exams. Because all company participants have this period at the same time this will not create a bottleneck, only a temporary stop in the continuous delivery.
\subsection{Test Completeness}
A test is considered complete when it passes the Gitlab pipeline, the selenium IDE-tests and exploratory testing for each merge. Not passing one of these tests means the merge request will not be approved.